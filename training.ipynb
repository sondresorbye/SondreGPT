{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning GPT to Mimic Myself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "load_dotenv()\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 595 JSON files\n",
      "Skipped 18704 messages from before 2019\n",
      "Skipped 1617 system messages from Messenger\n",
      "Skipped 254 group chats\n",
      "Loaded 78284 messages\n"
     ]
    }
   ],
   "source": [
    "json_files = glob.glob(\"./messenger-data/inbox/*/*.json\")\n",
    "assert len(json_files) > 0, \"No JSON message files found\"\n",
    "print(f\"Found {len(json_files)} JSON files\")\n",
    "number_of_group_chats = 0\n",
    "dataframes = []\n",
    "for json_file in json_files:\n",
    "    with open(json_file) as f:\n",
    "        data = json.load(f)\n",
    "        chat_title = data[\"title\"]\n",
    "        chat_id = data[\"thread_path\"].split(\"/\")[-1]\n",
    "        assert chat_title is not None and chat_id is not None\n",
    "        if chat_title == \"\":\n",
    "            continue\n",
    "        data[\"messages\"] = [m for m in data[\"messages\"] if \"content\" in m]\n",
    "        messages = [m[\"content\"] for m in data[\"messages\"]]\n",
    "        sender_names = [m[\"sender_name\"] for m in data[\"messages\"]]\n",
    "        timestamps = [m[\"timestamp_ms\"] for m in data[\"messages\"]]\n",
    "        if len(messages) == 0:\n",
    "            continue\n",
    "        if len(data[\"participants\"]) > 2:\n",
    "            number_of_group_chats += 1\n",
    "            continue\n",
    "        assert len(messages) == len(sender_names) == len(timestamps)\n",
    "        df = pd.DataFrame(\n",
    "            {\n",
    "                \"message\": messages,\n",
    "                \"sender_name\": sender_names,\n",
    "                \"timestamp\": timestamps,\n",
    "                \"chat_id\": chat_id,\n",
    "                \"chat_title\": chat_title,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit=\"ms\")\n",
    "        dataframes.append(df)\n",
    "\n",
    "data = pd.concat(dataframes)\n",
    "data = data.sort_values(by=[\"chat_id\", \"timestamp\"], ascending=True)\n",
    "# Filter out messages older than 2019\n",
    "len_before = len(data)\n",
    "data = data[data[\"timestamp\"] > \"2019-01-01\"]\n",
    "print(f\"Skipped {len_before - len(data)} messages from before 2019\")\n",
    "# Delete Messenger generated messages\n",
    "len_before = len(data)\n",
    "messenger_system_messages = [\n",
    "    \"The video chat ended.\",\n",
    "    \"You missed a call from\",\n",
    "    \"You missed a video chat with\",\n",
    "    \"You can now call each other\",\n",
    "    \"You can now video chat with each other\",\n",
    "    \"You can now chat with each other\",\n",
    "    \"You sent an attachment.\"\n",
    "]\n",
    "data = data[~data[\"message\"].str.contains('|'.join(messenger_system_messages))]\n",
    "print(f\"Skipped {len_before - len(data)} system messages from Messenger\")\n",
    "data = data.reset_index(drop=True)\n",
    "print(f\"Skipped {number_of_group_chats} group chats\")\n",
    "print(f\"Loaded {len(data)} messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>sender_name</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>chat_id</th>\n",
       "      <th>chat_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is the sublet from Facebook still available?</td>\n",
       "      <td>Sondre Sørbye</td>\n",
       "      <td>2023-06-10 20:55:28.394</td>\n",
       "      <td>adithyarao_3536258600025152</td>\n",
       "      <td>Adithya Rao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yup it is.</td>\n",
       "      <td>Adithya Rao</td>\n",
       "      <td>2023-06-11 01:24:57.739</td>\n",
       "      <td>adithyarao_3536258600025152</td>\n",
       "      <td>Adithya Rao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is it possible to only rent for the fall semes...</td>\n",
       "      <td>Sondre Sørbye</td>\n",
       "      <td>2023-06-11 14:14:31.199</td>\n",
       "      <td>adithyarao_3536258600025152</td>\n",
       "      <td>Adithya Rao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yup</td>\n",
       "      <td>Adithya Rao</td>\n",
       "      <td>2023-06-11 18:18:34.553</td>\n",
       "      <td>adithyarao_3536258600025152</td>\n",
       "      <td>Adithya Rao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fantastic, we have a deal. How many are you li...</td>\n",
       "      <td>Sondre Sørbye</td>\n",
       "      <td>2023-06-11 18:32:39.912</td>\n",
       "      <td>adithyarao_3536258600025152</td>\n",
       "      <td>Adithya Rao</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message    sender_name  \\\n",
       "0       Is the sublet from Facebook still available?  Sondre Sørbye   \n",
       "1                                         Yup it is.    Adithya Rao   \n",
       "2  Is it possible to only rent for the fall semes...  Sondre Sørbye   \n",
       "3                                                Yup    Adithya Rao   \n",
       "4  Fantastic, we have a deal. How many are you li...  Sondre Sørbye   \n",
       "\n",
       "                timestamp                      chat_id   chat_title  \n",
       "0 2023-06-10 20:55:28.394  adithyarao_3536258600025152  Adithya Rao  \n",
       "1 2023-06-11 01:24:57.739  adithyarao_3536258600025152  Adithya Rao  \n",
       "2 2023-06-11 14:14:31.199  adithyarao_3536258600025152  Adithya Rao  \n",
       "3 2023-06-11 18:18:34.553  adithyarao_3536258600025152  Adithya Rao  \n",
       "4 2023-06-11 18:32:39.912  adithyarao_3536258600025152  Adithya Rao  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fix_special_characters(text):\n",
    "    return re.sub(\n",
    "        r\"[\\xc2-\\xf4][\\x80-\\xbf]+\",\n",
    "        lambda m: m.group(0).encode(\"latin1\").decode(\"utf8\"),\n",
    "        text,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "data[\"message\"] = data[\"message\"].map(fix_special_characters)\n",
    "\n",
    "data[\"sender_name\"] = data[\"sender_name\"].map(fix_special_characters)\n",
    "\n",
    "data[\"chat_title\"] = data[\"chat_title\"].map(fix_special_characters)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping the data into a format suitable for GPT\n",
    "To fine-tune GPT, we need the data in the following format:\n",
    "```\n",
    "{\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"Marv is a factual chatbot that is also sarcastic.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"What's the capital of France?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"Paris, as if everyone doesn't know that already.\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "The example over is the format for one chat. I will create multiple chats where I consider a chat done if there have not been any messages for 10 hours. I will also include the name of the person who sent the message, so that the model can learn to chat with different people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME_OF_USER_TO_MIMIC = \"Sondre Sørbye\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaae1d73741a47b0a4855cabc1ddf2f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/219 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To give the model some context, we will include some of the previous messages in the prompt. I will use all messages from the last 5 hours. I will also include the name of the person who sent the message, so that the model can learn to chat with different people.\n",
    "def get_chats(df, hours_before_chat_dead=8):\n",
    "    chats = []\n",
    "    curr_timestamp = None\n",
    "    other_person = df.chat_title.unique()[0]\n",
    "    assert other_person is not None and isinstance(other_person, str)\n",
    "\n",
    "    def get_chat_start_map():\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": f\"Du er Sondre Sørbye, en 22 år gammel gutt fra Oslo. Dette er en chat mellom deg og {other_person}.\",\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "\n",
    "    curr_chat = get_chat_start_map()\n",
    "    for _, row in df.iterrows():\n",
    "        if curr_timestamp is None:\n",
    "            curr_timestamp = row[\"timestamp\"]\n",
    "        if (row[\"timestamp\"] - curr_timestamp).seconds / 3600 > hours_before_chat_dead:\n",
    "            # Start a new chat\n",
    "            chats.append(curr_chat)\n",
    "            curr_chat = get_chat_start_map()\n",
    "            curr_timestamp = row[\"timestamp\"]\n",
    "        role = \"assistant\" if row[\"sender_name\"] == NAME_OF_USER_TO_MIMIC else \"user\"\n",
    "        # Append the message to the previous message if it was sent by the same person\n",
    "        if len(curr_chat[\"messages\"]) > 0 and curr_chat[\"messages\"][-1][\"role\"] == role:\n",
    "            curr_chat[\"messages\"][-1][\"content\"] += \"\\n\" + row[\"message\"]\n",
    "        else:\n",
    "            curr_chat[\"messages\"].append(\n",
    "                {\n",
    "                    \"role\": role,\n",
    "                    \"content\": row[\"message\"],\n",
    "                }\n",
    "            )\n",
    "    # Append the last chat\n",
    "    chats.append(curr_chat)\n",
    "    return chats\n",
    "\n",
    "\n",
    "chats = data.groupby(\"chat_id\").progress_apply(get_chats).tolist()\n",
    "# Flatten the list\n",
    "chats = [chat for chat_list in chats for chat in chat_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_chat(chat):\n",
    "#     for message in chat[\"messages\"]:\n",
    "#         print(f\"{message['role']}: {message['content']}\")\n",
    "#     print(\"\\n\")\n",
    "\n",
    "# # Print 10 random chats\n",
    "# for _ in range(10):\n",
    "#     print_chat(np.random.choice(chats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Data Format Validation and Cost Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 453 chats with no response from the assistant (9.33%)\n"
     ]
    }
   ],
   "source": [
    "# Remove chats with no response from the assistant\n",
    "chat_len = len(chats)\n",
    "chats = [\n",
    "    chat for chat in chats if (any(m[\"role\"] == \"assistant\" for m in chat[\"messages\"]))\n",
    "]\n",
    "print(\n",
    "    f\"Removed {chat_len - len(chats)} chats with no response from the assistant ({(chat_len - len(chats)) / chat_len * 100:.2f}%)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "# Format error checks\n",
    "format_errors = defaultdict(int)\n",
    "\n",
    "for ex in chats:\n",
    "    if not isinstance(ex, dict):\n",
    "        format_errors[\"data_type\"] += 1\n",
    "        continue\n",
    "        \n",
    "    messages = ex.get(\"messages\", None)\n",
    "    if not messages:\n",
    "        format_errors[\"missing_messages_list\"] += 1\n",
    "        continue\n",
    "        \n",
    "    for message in messages:\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            format_errors[\"message_missing_key\"] += 1\n",
    "        \n",
    "        if any(k not in (\"role\", \"content\", \"name\", \"function_call\") for k in message):\n",
    "            format_errors[\"message_unrecognized_key\"] += 1\n",
    "        \n",
    "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "            format_errors[\"unrecognized_role\"] += 1\n",
    "            \n",
    "        content = message.get(\"content\", None)\n",
    "        function_call = message.get(\"function_call\", None)\n",
    "        \n",
    "        if (not content and not function_call) or not isinstance(content, str):\n",
    "            format_errors[\"missing_content\"] += 1\n",
    "    \n",
    "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "        format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "if format_errors:\n",
    "    print(\"Found errors:\")\n",
    "    for k, v in format_errors.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "else:\n",
    "    print(\"No errors found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 354\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 2, 347\n",
      "mean / median: 11.380822540331742, 7.0\n",
      "p5 / p95: 3.0, 25.0\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 46, 6290\n",
      "mean / median: 270.706203135651, 174.0\n",
      "p5 / p95: 70.0, 561.0\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 1, 4495\n",
      "mean / median: 72.2097250624858, 39.0\n",
      "p5 / p95: 7.0, 166.0\n",
      "\n",
      "5 examples may be over the 4096 token limit, they will be truncated during fine-tuning\n"
     ]
    }
   ],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# not exact!\n",
    "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n",
    "\n",
    "\n",
    "# Warnings and tokens counts\n",
    "n_missing_system = 0\n",
    "n_missing_user = 0\n",
    "n_messages = []\n",
    "convo_lens = []\n",
    "assistant_message_lens = []\n",
    "\n",
    "for ex in chats:\n",
    "    messages = ex[\"messages\"]\n",
    "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
    "        n_missing_system += 1\n",
    "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
    "        n_missing_user += 1\n",
    "    n_messages.append(len(messages))\n",
    "    convo_lens.append(num_tokens_from_messages(messages))\n",
    "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
    "    \n",
    "print(\"Num examples missing system message:\", n_missing_system)\n",
    "print(\"Num examples missing user message:\", n_missing_user)\n",
    "print_distribution(n_messages, \"num_messages_per_example\")\n",
    "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
    "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
    "n_too_long = sum(l > 4096 for l in convo_lens)\n",
    "print(f\"\\n{n_too_long} examples may be over the 4096 token limit, they will be truncated during fine-tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 4401 examples\n",
      "Dataset has ~1186834 tokens that will be charged for during training\n",
      "By default, you'll train for 4 epochs on this dataset\n",
      "By default, you'll be charged for ~4747336 tokens\n",
      "By default, this will cost ~$37.98\n"
     ]
    }
   ],
   "source": [
    "# Pricing and default n_epochs estimate\n",
    "MAX_TOKENS_PER_EXAMPLE = 4096\n",
    "\n",
    "TARGET_EPOCHS = 4\n",
    "MIN_TARGET_EXAMPLES = 100\n",
    "MAX_TARGET_EXAMPLES = 25000\n",
    "MIN_DEFAULT_EPOCHS = 1\n",
    "MAX_DEFAULT_EPOCHS = 25\n",
    "\n",
    "n_epochs = TARGET_EPOCHS\n",
    "n_train_examples = len(chats)\n",
    "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
    "    print(f\"Dataset is too small, you'll need to train for at least {MIN_DEFAULT_EPOCHS} epochs\")\n",
    "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
    "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
    "    print(f\"Dataset is too large, you'll need to train for at most {MAX_DEFAULT_EPOCHS} epochs\")\n",
    "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
    "\n",
    "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
    "print(f\"Dataset has {n_train_examples} examples\")\n",
    "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
    "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
    "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")\n",
    "# Price: gpt-3.5-turbo\t$0.0080 / 1K tokens\n",
    "print(f\"By default, this will cost ~${n_epochs * n_billing_tokens_in_dataset * 0.008 / 1000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start the Fine-Tuning Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training examples to a .jsonl file\n",
    "with open('training_examples.jsonl', 'w') as f:\n",
    "    for example in chats:\n",
    "        f.write(json.dumps(example) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    ")\n",
    "file_id = client.files.create(\n",
    "  file=open(\"training_examples.jsonl\", \"rb\"),\n",
    "  purpose='fine-tune'\n",
    ").id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = client.fine_tuning.jobs.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    training_file=file_id,\n",
    "    hyperparameters={\n",
    "        \"n_epochs\": n_epochs,\n",
    "    }\n",
    ").id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "succeeded\n"
     ]
    }
   ],
   "source": [
    "job = client.fine_tuning.jobs.retrieve(job_id)\n",
    "print(job.status)\n",
    "model_name = job.fine_tuned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adithya Rao: Hi, what have you been up to today?\n",
      "Sondre Sørbye: Lecture\n",
      "Adithya Rao: Oh wow, what lecture?\n",
      "Sondre Sørbye: Operating systems\n",
      "Adithya Rao: want to go to the gym today?\n",
      "Sondre Sørbye: Have been there already. Want to go on a easy run?\n",
      "Adithya Rao: sure\n",
      "Sondre Sørbye: I would have asked neverland if he knows how to do this\n",
      "Adithya Rao: sure what?\n",
      "Sondre Sørbye: You're his proje assesment buddy\n",
      "Adithya Rao: what are you talking about?\n",
      "Sondre Sørbye: The thing I sent you\n",
      "Adithya Rao: You have not sent me anything?\n",
      "Sondre Sørbye: You didn't ask me how you would integrate the reward system?\n",
      "Exiting\n"
     ]
    }
   ],
   "source": [
    "PERSON_TO_CHAT_WITH = \"Adithya Rao\"\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"Du er Sondre Sørbye, en 22 år gammel gutt fra Oslo. Dette er en chat mellom deg og {PERSON_TO_CHAT_WITH}.\",\n",
    "    },\n",
    "]\n",
    "\n",
    "while True:\n",
    "    message = input(f\"{PERSON_TO_CHAT_WITH}: \")\n",
    "    if message == \"quit\" or message == \"exit\" or message == \"stop\" or message == \"q\" or message == \"\":\n",
    "        print(\"Exiting\")\n",
    "        break\n",
    "    print(f\"{PERSON_TO_CHAT_WITH}: {message}\")\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": message,\n",
    "        }\n",
    "    )\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=messages,\n",
    "\n",
    "    )\n",
    "    response = response.choices[0].message.content\n",
    "    print(f\"{NAME_OF_USER_TO_MIMIC}: {response}\")\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": response,\n",
    "        }\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
